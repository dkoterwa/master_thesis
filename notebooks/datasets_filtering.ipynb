{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Notebook to prepare test datasets / some of the database datasets and push them to Hugging Face <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "from tqdm import  tqdm\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> OASST <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550a1fcf99ef41e4b0fa9b40e5c44c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f296dc7727e14e948f591633c92f84ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/63.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14724e1727074265bb6f1f0adb5f321e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.18M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8c219a971746c8b5733ece5a1f2e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/128575 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60db607f43d84246ab2ca7206cac539f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/6599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "oass_train = load_dataset(\"OpenAssistant/oasst2\", split=\"train\").to_pandas()\n",
    "oass_valid = load_dataset(\"OpenAssistant/oasst2\", split=\"validation\").to_pandas()\n",
    "oass_full = pd.concat([oass_train, oass_valid,])\n",
    "oass_full.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_result\n",
       "True     129517\n",
       "False      3158\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oass_full[\"review_result\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lang: en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [04:04<20:20, 244.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lang: ar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [04:04<06:42, 100.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lang: de\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [04:25<03:13, 64.52s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lang: es\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [06:16<02:45, 82.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lang: vi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [06:17<00:53, 53.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lang: zh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [06:48<00:00, 68.14s/it]\n",
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.456 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "oass_train = load_dataset(\"OpenAssistant/oasst2\", split=\"train\").to_pandas()\n",
    "oass_valid = load_dataset(\"OpenAssistant/oasst2\", split=\"validation\").to_pandas()\n",
    "oass_full = pd.concat([oass_train, oass_valid,])\n",
    "oass_full.reset_index(drop=True, inplace=True)\n",
    "\n",
    "needed_langs = [\"en\", \"ar\", \"de\", \"es\", \"vi\", \"zh\"]\n",
    "rows = []\n",
    "for lang in tqdm(needed_langs):\n",
    "    print(f\"Processing lang: {lang}\")\n",
    "    filtered_df = oass_full[(oass_full[\"lang\"] == lang) & (oass_full[\"role\"] == \"assistant\")]\n",
    "    for i, answer in filtered_df.iterrows():\n",
    "        query = oass_full[oass_full[\"message_id\"] == answer[\"parent_id\"]][\"text\"].iloc[0]\n",
    "        rows.append([answer[\"lang\"], answer[\"message_id\"], answer[\"parent_id\"], answer[\"user_id\"], answer[\"created_date\"], query, answer[\"text\"], answer[\"review_count\"]])\n",
    "        \n",
    "filtered_dataset = pd.DataFrame(rows, columns=[\"lang\", \"message_id\", \"parent_id\", \"user_id\", \"created_date\", \"query\", \"answer\", \"review_count\"])\n",
    "filtered_dataset.drop_duplicates(subset=\"answer\", inplace=True)\n",
    "filtered_dataset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "filtered_dataset[\"answer_len\"] = [len(row[\"answer\"].split(\" \")) if row[\"lang\"] != \"zh\" else len(jieba.lcut(row[\"answer\"])) for _, row in filtered_dataset.iterrows()]\n",
    "filtered_dataset = filtered_dataset[filtered_dataset[\"answer_len\"] >= 20]\n",
    "filtered_dataset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f3bc6522954cfd89c2cb7def3a0c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcbbe0fbb44b481192a393b67caddc40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2610adde039b45ceae032823de12542a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/2.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/dkoterwa/oasst2_filtered/commit/d754d91215e924995a71201201b9d2921d545611', commit_message='Upload dataset', commit_description='', oid='d754d91215e924995a71201201b9d2921d545611', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset = Dataset.from_pandas(filtered_dataset)\n",
    "hf_dataset.push_to_hub(\"dkoterwa/oasst2_filtered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> MKQA <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkqa = load_dataset(\"mkqa\", split=\"train\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_langs = [\"en\", \"ar\", \"de\", \"es\", \"vi\", \"zh_cn\"]\n",
    "rows = []\n",
    "for i, row in tqdm(mkqa.iterrows(), total=mkqa.shape[0]):\n",
    "    for lang in needed_langs:\n",
    "        rows.append([lang, row[\"example_id\"], row[\"queries\"][lang], row[\"answers\"][lang][0][\"text\"]])\n",
    "        \n",
    "filtered_dataset = pd.DataFrame(rows, columns=[\"lang\", \"example_id\", \"query\", \"answer\"])\n",
    "filtered_dataset.dropna(inplace=True)\n",
    "filtered_dataset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = Dataset.from_pandas(filtered_dataset)\n",
    "hf_dataset.push_to_hub(\"dkoterwa/mkqa_filtered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> MLQA <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mlqa(subset_name):\n",
    "    dataset_valid = load_dataset(\"mlqa\", subset_name, split=\"validation\").to_pandas()\n",
    "    dataset_test  = load_dataset(\"mlqa\", subset_name, split=\"test\").to_pandas()\n",
    "    full_dataset = pd.concat([dataset_valid, dataset_test])\n",
    "    full_dataset.reset_index(drop=True, inplace=True)\n",
    "    return full_dataset\n",
    "\n",
    "needed_langs = [\"mlqa.en.en\", \"mlqa.de.de\", \"mlqa.ar.ar\", \"mlqa.es.es\", \"mlqa.vi.vi\", \"mlqa.zh.zh\"]\n",
    "datasets = []\n",
    "for lang in tqdm(needed_langs):\n",
    "    dataset = download_mlqa(lang)\n",
    "    dataset[\"lang\"] = lang.split(\".\")[2]\n",
    "    datasets.append(dataset)\n",
    "    \n",
    "full_mlqa = pd.concat(datasets)\n",
    "full_mlqa.reset_index(drop=True, inplace=True)\n",
    "full_mlqa[\"answer\"] = [answer_dict[\"text\"][0] for answer_dict in full_mlqa[\"answers\"]]\n",
    "full_mlqa.drop(\"answers\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = Dataset.from_pandas(full_mlqa)\n",
    "hf_dataset.push_to_hub(\"dkoterwa/mlqa_filtered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Database datasets <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\"FreedomIntelligence/alpaca-gpt4-deutsch\": \"de\",\n",
    "            \"FreedomIntelligence/alpaca-gpt4-spanish\": \"es\",\n",
    "            \"FreedomIntelligence/alpaca-gpt4-chinese\": \"zh\",\n",
    "            \"FreedomIntelligence/alpaca-gpt4-arabic\": \"ar\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name, language in datasets.items():\n",
    "    dataset = load_dataset(dataset_name, split=\"train\").to_pandas()\n",
    "    dataset[\"answer\"] = [conversation[1][\"value\"] for conversation in dataset[\"conversations\"]]\n",
    "    dataset[\"instruction\"] = [conversation[0][\"value\"] for conversation in dataset[\"conversations\"]]\n",
    "    dataset.drop(\"conversations\", axis=1, inplace=True)\n",
    "    hf_dataset = Dataset.from_pandas(dataset)\n",
    "    hf_dataset.push_to_hub(f\"dkoterwa/alpaca_gpt_4_{language}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
