{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "from tqdm import  tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> OASST <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oass_train = load_dataset(\"OpenAssistant/oasst2\", split=\"train\").to_pandas()\n",
    "oass_valid = load_dataset(\"OpenAssistant/oasst2\", split=\"validation\").to_pandas()\n",
    "oass_full = pd.concat([oass_train, oass_valid,])\n",
    "oass_full.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oass_full[\"review_result\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oass_train = load_dataset(\"OpenAssistant/oasst2\", split=\"train\").to_pandas()\n",
    "oass_valid = load_dataset(\"OpenAssistant/oasst2\", split=\"validation\").to_pandas()\n",
    "oass_full = pd.concat([oass_train, oass_valid,])\n",
    "oass_full.reset_index(drop=True, inplace=True)\n",
    "\n",
    "needed_langs = [\"en\", \"ar\", \"de\", \"es\", \"vi\", \"zh\"]\n",
    "rows = []\n",
    "for lang in tqdm(needed_langs):\n",
    "    print(f\"Processing lang: {lang}\")\n",
    "    filtered_df = oass_full[(oass_full[\"lang\"] == lang) & (oass_full[\"role\"] == \"assistant\")]\n",
    "    for i, answer in filtered_df.iterrows():\n",
    "        query = oass_full[oass_full[\"message_id\"] == answer[\"parent_id\"]][\"text\"].iloc[0]\n",
    "        rows.append([answer[\"lang\"], answer[\"message_id\"], answer[\"parent_id\"], answer[\"user_id\"], answer[\"created_date\"], query, answer[\"text\"], answer[\"review_count\"]])\n",
    "        \n",
    "filtered_dataset = pd.DataFrame(rows, columns=[\"lang\", \"message_id\", \"parent_id\", \"user_id\", \"created_date\", \"query\", \"answer\", \"review_count\"])\n",
    "filtered_dataset.drop_duplicates(subset=\"answer\", inplace=True)\n",
    "filtered_dataset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = Dataset.from_pandas(filtered_dataset)\n",
    "hf_dataset.push_to_hub(\"dkoterwa/oasst2_filtered_retrieval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> MKQA <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkqa = load_dataset(\"mkqa\", split=\"train\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_langs = [\"en\", \"ar\", \"de\", \"es\", \"vi\", \"zh_cn\"]\n",
    "rows = []\n",
    "for i, row in tqdm(mkqa.iterrows(), total=mkqa.shape[0]):\n",
    "    for lang in needed_langs:\n",
    "        rows.append([lang, row[\"example_id\"], row[\"queries\"][lang], row[\"answers\"][lang][0][\"text\"]])\n",
    "        \n",
    "filtered_dataset = pd.DataFrame(rows, columns=[\"lang\", \"example_id\", \"query\", \"answer\"])\n",
    "filtered_dataset.dropna(inplace=True)\n",
    "filtered_dataset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = Dataset.from_pandas(filtered_dataset)\n",
    "hf_dataset.push_to_hub(\"dkoterwa/mkqa_filtered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> MLQA <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mlqa(subset_name):\n",
    "    dataset_valid = load_dataset(\"mlqa\", subset_name, split=\"validation\").to_pandas()\n",
    "    dataset_test  = load_dataset(\"mlqa\", subset_name, split=\"test\").to_pandas()\n",
    "    full_dataset = pd.concat([dataset_valid, dataset_test])\n",
    "    full_dataset.reset_index(drop=True, inplace=True)\n",
    "    return full_dataset\n",
    "\n",
    "needed_langs = [\"mlqa.en.en\", \"mlqa.de.de\", \"mlqa.ar.ar\", \"mlqa.es.es\", \"mlqa.vi.vi\", \"mlqa.zh.zh\"]\n",
    "datasets = []\n",
    "for lang in tqdm(needed_langs):\n",
    "    dataset = download_mlqa(lang)\n",
    "    dataset[\"lang\"] = lang.split(\".\")[2]\n",
    "    datasets.append(dataset)\n",
    "    \n",
    "full_mlqa = pd.concat(datasets)\n",
    "full_mlqa.reset_index(drop=True, inplace=True)\n",
    "full_mlqa[\"answer\"] = [answer_dict[\"text\"][0] for answer_dict in full_mlqa[\"answers\"]]\n",
    "full_mlqa.drop(\"answers\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 42/42 [00:00<00:00, 291.74ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:20<00:00, 20.74s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/dkoterwa/mlqa_filtered/commit/40cef1342702318a0219d89a7b7828ebda5180b7', commit_message='Upload dataset', commit_description='', oid='40cef1342702318a0219d89a7b7828ebda5180b7', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset = Dataset.from_pandas(full_mlqa)\n",
    "hf_dataset.push_to_hub(\"dkoterwa/mlqa_filtered\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
